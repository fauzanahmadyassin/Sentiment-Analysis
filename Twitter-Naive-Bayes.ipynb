{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "STANDARD CLASSIFICATION :\n",
      "\n",
      "Accuracy on iteration 1 : 0.834\n",
      "Accuracy on iteration 2 : 0.813\n",
      "Accuracy on iteration 3 : 0.832\n",
      "Accuracy on iteration 4 : 0.817\n",
      "Accuracy on iteration 5 : 0.817\n",
      "Accuracy on iteration 6 : 0.840\n",
      "Accuracy on iteration 7 : 0.817\n",
      "Accuracy on iteration 8 : 0.841\n",
      "Accuracy on iteration 9 : 0.825\n",
      "Accuracy on iteration 10 : 0.832\n",
      "\n",
      "ITERATION COMPLETE!\n",
      "\n",
      "______________________________________________________________________________\n",
      "\n",
      "Documents name : Car_Review.csv\n",
      "\n",
      "Accuracy : 0.841\n",
      "Iteration number : 8\n",
      "\n",
      "Confusion Matrix : \n",
      "\n",
      "Predicted  Negative  Positive  All\n",
      "Actual                            \n",
      "Negative        282        48  330\n",
      "Positive         59       284  343\n",
      "All             341       332  673\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.83      0.85      0.84       330\n",
      "   Positive       0.86      0.83      0.84       343\n",
      "\n",
      "avg / total       0.84      0.84      0.84       673\n",
      "\n",
      "______________________________________________________________________________\n",
      "\n",
      "\n",
      "CLASSIFICATION ON CROSS VALIDATION :\n",
      "\n",
      "Accuracy on iteration 1 with maximum at fold 3 : 0.879\n",
      "Accuracy on iteration 2 with maximum at fold 3 : 0.848\n",
      "Accuracy on iteration 3 with maximum at fold 4 : 0.866\n",
      "Accuracy on iteration 4 with maximum at fold 2 : 0.858\n",
      "Accuracy on iteration 5 with maximum at fold 3 : 0.862\n",
      "Accuracy on iteration 6 with maximum at fold 7 : 0.866\n",
      "Accuracy on iteration 7 with maximum at fold 1 : 0.840\n",
      "Accuracy on iteration 8 with maximum at fold 9 : 0.871\n",
      "Accuracy on iteration 9 with maximum at fold 3 : 0.853\n",
      "Accuracy on iteration 10 with maximum at fold 10 : 0.884\n",
      "\n",
      "ITERATION COMPLETE!\n",
      "\n",
      "______________________________________________________________________________\n",
      "\n",
      "Documents name : Car_Review.csv\n",
      "Highest accuracy on KFold Validation is on fold 10 in iteration 10 :\n",
      "Accuracy : 0.884\n",
      "\n",
      "Confusion Matrix : \n",
      "\n",
      "Predicted  Negative  Positive  All\n",
      "Actual                            \n",
      "Negative        102        13  115\n",
      "Positive         13        96  109\n",
      "All             115       109  224\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.89      0.89      0.89       115\n",
      "   Positive       0.88      0.88      0.88       109\n",
      "\n",
      "avg / total       0.88      0.88      0.88       224\n",
      "\n",
      "______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import sys,tweepy,csv,re\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn import cross_validation\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "class SentimentAnalysis:\n",
    "\n",
    "    def MainProcess(self):\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df_corpus = pd.DataFrame()\n",
    "        df_tfidf = pd.DataFrame()\n",
    "        df_result_pred = pd.DataFrame()\n",
    "        #################################\n",
    "        df = pd.read_csv('zidane_resample.csv')\n",
    "        doc = 'Zidane_Review'\n",
    "        #################################\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        #display (df)\n",
    "        \n",
    "        ###########################################  after delete the digit\n",
    "        #df_tfidf = pd.read_csv('corpus-honda-clean.csv')\n",
    "        #display (df_tfidf)\n",
    "        ###########################################\n",
    "        \n",
    "        #df_corpus = self.Corpus(df.Tweet)\n",
    "        #display (df_corpus)\n",
    "        \n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        \n",
    "        for x in df.Polarity_Class:\n",
    "            if x == 'Positive':\n",
    "                pos_count += 1\n",
    "            elif x == 'Negative':\n",
    "                neg_count += 1\n",
    "                \n",
    "        \n",
    "        iteration = 10\n",
    "        max_accuracy = 0\n",
    "        max_con_matrix = 0\n",
    "        max_report = 0\n",
    "        max_iter = 0\n",
    "        kfold_accuracy = 0\n",
    "        kfold_con_matrix = 0\n",
    "        kfold_report = 0\n",
    "        kfold_fold = 0\n",
    "        kfold_iter = 0\n",
    "        fkfold_accuracy = 0\n",
    "        fkfold_con_matrix = 0\n",
    "        fkfold_report = 0\n",
    "        fkfold_fold = 0\n",
    "        fkfold_iter = 0\n",
    "        store = []\n",
    "        df_store = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        # ITERATION\n",
    "        \n",
    "        ###############################################################################################    \n",
    "        print ('______________________________________________________________________________\\n') \n",
    "        print ('STANDARD CLASSIFICATION :\\n')       \n",
    "        for i in range (iteration):\n",
    "            \n",
    "            test_size,accuracy,con_matrix,report = self.NaiveBayes(df.Polarity_Class, df.Tweet)\n",
    "            if float(accuracy) > float(max_accuracy):\n",
    "                max_accuracy = accuracy\n",
    "                max_con_matrix = con_matrix\n",
    "                max_report = report\n",
    "                max_iter = str(i+1)\n",
    "                \n",
    "            print ('Accuracy on iteration ' +str(i+1)+ ' : ' +str(format(accuracy, '.3f')))\n",
    "           \n",
    "        print ('\\nITERATION COMPLETE!') \n",
    "        print ('\\n______________________________________________________________________________')\n",
    "        print ('\\nDocuments name : ' +str(doc)+ '.csv') \n",
    "        print ('\\nAccuracy : '+ str(format(max_accuracy, '.3f')))\n",
    "        print ('Iteration number : ' +str(max_iter))\n",
    "        print ('\\nConfusion Matrix : \\n\\n' +str(max_con_matrix))\n",
    "        print ('\\nClassification Report : \\n\\n' +str(max_report))\n",
    "        print ('______________________________________________________________________________\\n')\n",
    "        \n",
    "        print ('\\nCLASSIFICATION ON CROSS VALIDATION :\\n')       \n",
    "        for i in range (iteration):\n",
    "            \n",
    "            kmax_accuracy,kmax_con_matrix,kmax_report,kno_fold = self.KFold(df.Polarity_Class, df.Tweet)\n",
    "            if float(kmax_accuracy) > float(kfold_accuracy):\n",
    "                kfold_accuracy = kmax_accuracy\n",
    "                kfold_con_matrix = kmax_con_matrix\n",
    "                kfold_report = kmax_report\n",
    "                kfold_fold = kno_fold\n",
    "                kfold_iter = str(i+1)\n",
    "            print ('Accuracy on iteration ' +str(i+1)+ ' with maximum at fold ' +str(kno_fold)+ ' : ' +str(format(kmax_accuracy, '.3f')))\n",
    "                \n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "        print ('\\nITERATION COMPLETE!') \n",
    "        print ('\\n______________________________________________________________________________')\n",
    "        print ('\\nDocuments name : ' +str(doc)+ '.csv')\n",
    "        print ('Highest accuracy on KFold Validation is on fold '+str(kfold_fold)+' in iteration ' +str(kfold_iter)+ ' :')\n",
    "        print ('Accuracy : '+str(format(kfold_accuracy, '.3f')))\n",
    "        print ('\\nConfusion Matrix : \\n\\n' +str(kfold_con_matrix))\n",
    "        print ('\\nClassification Report : \\n\\n' +str(kfold_report))\n",
    "        print ('______________________________________________________________________________')\n",
    "        \n",
    "        \n",
    "        ###############################################################################################\n",
    "\n",
    "                                                                                                          \n",
    "        '''\n",
    "        # NO ITERATION\n",
    "        ###############################################################################################\n",
    "        test_size,accuracy,con_matrix,report = self.NaiveBayes(df.Polarity_Class, df.Tweet)\n",
    "        \n",
    "        print ('\\nDocuments name : ' +str(doc)+ '.csv')\n",
    "        print ('Testing size : ' +str(test_size*100)+'%')\n",
    "        print ('Total positive tweets : ' +str(pos_count))\n",
    "        print ('Total negative tweets : ' +str(neg_count))\n",
    "        print ('\\nAccuracy : '+str(format(accuracy, '.3f')))   \n",
    "        print ('\\nConfusion Matrix : \\n' +str(con_matrix))\n",
    "        print ('\\nClassification Report : \\n' +str(report))\n",
    "      \n",
    "        \n",
    "        max_accuracy,max_con_matrix,max_report,no_fold = self.KFold(df.Polarity_Class, df.Tweet)\n",
    "        \n",
    "        print ('\\nDocuments name : ' +str(doc)+ '.csv')\n",
    "        print ('\\nHighest accuracy on KFold Validation is on fold '+str(no_fold)+' :')\n",
    "        print ('Accuracy : '+str(format(max_accuracy, '.3f')))\n",
    "        print ('\\nConfusion Matrix : \\n' +str(max_con_matrix))\n",
    "        print ('\\nClassification Report : \\n' +str(max_report))\n",
    "                \n",
    "        ###############################################################################################\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def Corpus(self, Tweet):\n",
    "        \n",
    "        doc = []\n",
    "        vectorizer = TfidfVectorizer(use_idf=True, strip_accents='ascii')\n",
    "        \n",
    "        for x in Tweet:\n",
    "            doc.append((str(x)).lower())         \n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(str(doc))\n",
    "        \n",
    "        fw = [w for w in tokens if not w in stop_words]\n",
    "        fw = []\n",
    "        #filtered_words = [x for x in fw if not any(c.isdigit() for c in x)]\n",
    "        filtered_words = [item for item in fw if item.isalpha()]\n",
    "        filtered_words = []\n",
    "        \n",
    "        ps = PorterStemmer()\n",
    "        for t in tokens:\n",
    "            if t not in stop_words:\n",
    "                w = ps.stem(t)\n",
    "                filtered_words.append(w)  \n",
    "                \n",
    "        temp = vectorizer.fit_transform(filtered_words) \n",
    "        \n",
    "        vocab = vectorizer.get_feature_names()\n",
    "        temp = temp.toarray()\n",
    "        dist = np.sum(temp, axis=0)\n",
    "        df = pd.DataFrame()\n",
    "        list1 = []\n",
    "        list2 = []\n",
    "        \n",
    "        for w,c in zip(vocab, dist):\n",
    "            list1.append(w)\n",
    "            list2.append(c)\n",
    "            \n",
    "        \n",
    "      \n",
    "        df['Vocabulary'] = list1\n",
    "        #df['Word_count'] = list2\n",
    "        df['TF-IDF'] = list2\n",
    "        \n",
    "        df.to_csv('corpus-honda.csv', sep=',', index=False, encoding='utf-8')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def KFold(self, Class, Tweet):\n",
    "        \n",
    "        stopset = set(stopwords.words('english'))\n",
    "        vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)\n",
    "        \n",
    "        y = Class\n",
    "        X = vectorizer.fit_transform(Tweet)\n",
    "        \n",
    "        kf = KFold(n_splits=10) \n",
    "        kf.get_n_splits(X) \n",
    "        \n",
    "        clf = naive_bayes.MultinomialNB()\n",
    "        \n",
    "        count = 1\n",
    "        count = int(count)\n",
    "        \n",
    "        max_accuracy = 0\n",
    "        max_con_matrix = 0\n",
    "        max_report = 0\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            #print ('\\nAccuracy on K-fold Validation ' +str(count)+ ' : ')\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            con_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "            report = classification_report(y_test, y_pred)\n",
    "            \n",
    "            #print ('Accuracy : '+str(format(accuracy, '.3f')))\n",
    "            #print ('\\nConfusion Matrix : \\n' +str(con_matrix))\n",
    "            #print ('\\nClassification Report : \\n' +str(report))\n",
    "            \n",
    "            if float(accuracy) > float(max_accuracy):\n",
    "                max_accuracy = accuracy\n",
    "                max_con_matrix = con_matrix\n",
    "                max_report = report\n",
    "                no_fold = count\n",
    "            count +=1\n",
    "            \n",
    "        return max_accuracy, max_con_matrix, max_report, no_fold\n",
    "            \n",
    "\n",
    "    def NaiveBayes(self, Class, Tweet):\n",
    "        \n",
    "        stopset = set(stopwords.words('english'))\n",
    "        vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)\n",
    "      \n",
    "        y = Class\n",
    "        X = vectorizer.fit_transform(Tweet)\n",
    "        \n",
    "        #test_size = float(raw_input(\"Enter the percentage of testing set: \"))\n",
    "        test_size = 0.3\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=test_size)\n",
    "        clf = naive_bayes.MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        con_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        return test_size,accuracy,con_matrix,report\n",
    "\n",
    "        \n",
    "if __name__== \"__main__\":\n",
    "    sa = SentimentAnalysis()\n",
    "    sa.MainProcess() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
